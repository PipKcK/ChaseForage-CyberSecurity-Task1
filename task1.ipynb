{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb163b7b",
   "metadata": {
    "id": "bb163b7b"
   },
   "source": [
    "Step 1. Ensure that you have the dataset file named `transactions.csv` in the current directory.\n",
    "\n",
    "The dataset is a subset of https://www.kaggle.com/ealaxi/paysim1/version/2 which was originally generated as part of the following research:\n",
    "\n",
    "E. A. Lopez-Rojas , A. Elmir, and S. Axelsson. \"PaySim: A financial mobile money simulator for fraud detection\". In: The 28th European Modeling and Simulation Symposium-EMSS, Larnaca, Cyprus. 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c898bd",
   "metadata": {
    "id": "72c898bd"
   },
   "source": [
    "Step 2. Complete the following exercises.\n",
    "\n",
    "0. Read the dataset (`transactions.csv`) as a Pandas dataframe. Note that the first row of the CSV contains the column names.\n",
    "\n",
    "0. Return the column names as a list from the dataframe.\n",
    "\n",
    "0. Return the first k rows from the dataframe.\n",
    "\n",
    "0. Return a random sample of k rows from the dataframe.\n",
    "\n",
    "0. Return a list of the unique transaction types.\n",
    "\n",
    "0. Return a Pandas series of the top 10 transaction destinations with frequencies.\n",
    "\n",
    "0. Return all the rows from the dataframe for which fraud was detected.\n",
    "\n",
    "0. Bonus. Return a dataframe that contains the number of distinct destinations that each source has interacted with to, sorted in descending order. You will find [groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) and [agg](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html) useful. The predefined aggregate functions are under `pandas.core.groupby.GroupBy.*`. See the [left hand column](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f146b9d",
   "metadata": {
    "id": "2f146b9d"
   },
   "source": [
    "Use the empty cell to test the exercises. If you modify the original `df`, you can rerun the cell containing `exercise_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EDd3m5pMN01e",
   "metadata": {
    "id": "EDd3m5pMN01e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def exercise_0(file):\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "def exercise_1(df):\n",
    "    return df.columns.tolist()\n",
    "\n",
    "def exercise_2(df, k):\n",
    "    return df.head(k)\n",
    "\n",
    "def exercise_3(df, k):\n",
    "    return df.sample(k)\n",
    "\n",
    "def exercise_4(df):\n",
    "    return df.type.unique().tolist()\n",
    "\n",
    "def exercise_5(df):\n",
    "    return df.nameDest.value_counts().head(10)\n",
    "\n",
    "def exercise_6(df):\n",
    "    return df[df.isFraud == 1]\n",
    "\n",
    "def exercise_7(df):\n",
    "    df_groupby_name_dest = df.groupby(\"nameDest\")[\"newbalanceDest\"].agg(\"mean\")\n",
    "    df_sorted_values = df_groupby_name_dest.sort_values(ascending=False)\n",
    "    return df_sorted_values\n",
    "\n",
    "def visual_1(df):\n",
    "    def transaction_counts(df):\n",
    "        return df.type.value_counts()\n",
    "    def transaction_counts_split_by_fraud(df):\n",
    "        filtered_df = df[df['isFraud'] == 1]\n",
    "        frequency_counts = filtered_df['type'].value_counts()\n",
    "        return frequency_counts\n",
    "\n",
    "    fig, axs = plt.subplots(2, figsize=(6,10))\n",
    "\n",
    "    transaction_counts(df).plot(ax=axs[0], kind='bar', width=0.6, rot=90)\n",
    "    axs[0].set_title('Transaction Counts')\n",
    "    axs[0].set_xlabel('Transaction Type')\n",
    "    axs[0].set_ylabel('Count')\n",
    "    plt.xticks(rotation=0)\n",
    "    axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=0)\n",
    "    transaction_counts_split_by_fraud(df).plot(ax=axs[1], kind='bar', width=0.2)\n",
    "    axs[1].set_title('Transaction Counts for Fraudulent Transactions')\n",
    "    axs[1].set_xlabel('Transaction Type')\n",
    "    axs[1].set_ylabel('Count')\n",
    "    axs[1].set_xticklabels(axs[1].get_xticklabels(), rotation=0)\n",
    "    fig.suptitle('Transaction Analysis')\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "    for ax in axs:\n",
    "      for p in ax.patches:\n",
    "          ax.annotate(p.get_height(), (p.get_x(), p.get_height()))\n",
    "    plt.show()\n",
    "    return 'The chart displaying transaction types and the number of fraudulent transactions is relevant as it helps identify patterns in fraud and assess the risk associated with different transaction types.'\n",
    "\n",
    "def visual_2(df):\n",
    "    def query(df):\n",
    "        temp_df = df[df['type'] == 'CASH_OUT'].copy()\n",
    "        column1 = temp_df['oldbalanceOrg'] - temp_df['newbalanceOrig']\n",
    "        column2 = temp_df['oldbalanceDest'] - temp_df['newbalanceDest']\n",
    "        new_df = pd.DataFrame({'OriginAccount Balance Delta': column1, 'DestinationAccount Balance Delta': column2})\n",
    "        print(new_df)\n",
    "        return new_df\n",
    "\n",
    "    new_df = query(df)\n",
    "    plot = new_df.plot.scatter(x='OriginAccount Balance Delta', y='DestinationAccount Balance Delta')\n",
    "    plot.set_title('Balance Delta Scatter Plot')\n",
    "    plot.set_xlim(left=-1e3, right=1e3)\n",
    "    plot.set_ylim(bottom=-1e3, top=1e3)\n",
    "    plt.show()\n",
    "    return 'Understanding the scatter plot depicting the relationship between the delta of origin account balance and destination account balance for Cash Out transactions is critical because it enables the detection of potential irregularities or instances of fraudulent behaviour within the financial ecosystem.'\n",
    "\n",
    "def exercise_custom(df, step):\n",
    "    step_data = df[df['step'] == step]\n",
    "    type_counts = step_data['type'].value_counts().reset_index()\n",
    "    type_counts.columns = ['type', 'frequency']\n",
    "    \n",
    "    all_types = df['type'].unique()\n",
    "    missing_types = list(set(all_types) - set(type_counts['type']))\n",
    "    missing_counts = pd.DataFrame({'type': missing_types, 'frequency': 0})\n",
    "    \n",
    "    step_df = pd.concat([type_counts, missing_counts], ignore_index=True)\n",
    "    return step_df\n",
    "    \n",
    "def visual_custom(df):\n",
    "    def visual_custom(df, step):\n",
    "    step_df = exercise_custom(df, step)\n",
    "    \n",
    "    labels = step_df['type']\n",
    "    frequencies = step_df['frequency']\n",
    "    \n",
    "    plt.pie(frequencies, labels=labels, autopct='%1.1f%%')\n",
    "    plt.axis('equal')\n",
    "    plt.title(f'Pie Chart for Step {step}')\n",
    "    plt.show()\n",
    "    return 'The pie charts purpose in this context is to provide a visual representation of the proportional distribution of different types within a specific step.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346fc3fc",
   "metadata": {
    "id": "346fc3fc"
   },
   "outputs": [],
   "source": [
    "df = exercise_0('transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9158f0bd",
   "metadata": {
    "id": "9158f0bd"
   },
   "outputs": [],
   "source": [
    "# Test exercises here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2dc2f4",
   "metadata": {
    "id": "ed2dc2f4"
   },
   "source": [
    "Create graphs for the following. \n",
    "1. Transaction types bar chart, Transaction types split by fraud bar chart\n",
    "1. Origin account balance delta v. Destination account balance delta scatter plot for Cash Out transactions\n",
    "\n",
    "Ensure that the graphs have the following:\n",
    " - Title\n",
    " - Labeled Axes\n",
    " \n",
    "The function plot the graph and then return a string containing a short description explaining the relevance of the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab229b34",
   "metadata": {
    "id": "ab229b34"
   },
   "outputs": [],
   "source": [
    "def visual_1(df):\n",
    "    def transaction_counts(df):\n",
    "        return df.type.value_counts()\n",
    "    def transaction_counts_split_by_fraud(df):\n",
    "        filtered_df = df[df['isFraud'] == 1]\n",
    "        frequency_counts = filtered_df['type'].value_counts()\n",
    "        return frequency_counts\n",
    "\n",
    "    fig, axs = plt.subplots(2, figsize=(6,10))\n",
    "\n",
    "    transaction_counts(df).plot(ax=axs[0], kind='bar', width=0.6, rot=90)\n",
    "    axs[0].set_title('Transaction Counts')\n",
    "    axs[0].set_xlabel('Transaction Type')\n",
    "    axs[0].set_ylabel('Count')\n",
    "    plt.xticks(rotation=0)\n",
    "    axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=0)\n",
    "    transaction_counts_split_by_fraud(df).plot(ax=axs[1], kind='bar', width=0.2)\n",
    "    axs[1].set_title('Transaction Counts for Fraudulent Transactions')\n",
    "    axs[1].set_xlabel('Transaction Type')\n",
    "    axs[1].set_ylabel('Count')\n",
    "    axs[1].set_xticklabels(axs[1].get_xticklabels(), rotation=0)\n",
    "    fig.suptitle('Transaction Analysis')\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "    for ax in axs:\n",
    "      for p in ax.patches:\n",
    "          ax.annotate(p.get_height(), (p.get_x(), p.get_height()))\n",
    "    plt.show()\n",
    "    return 'The chart displaying transaction types and the number of fraudulent transactions is relevant as it helps identify patterns in fraud and assess the risk associated with different transaction types.'\n",
    "visual_1(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab2f47",
   "metadata": {
    "id": "38ab2f47"
   },
   "outputs": [],
   "source": [
    "def visual_2(df):\n",
    "    def query(df):\n",
    "        temp_df = df[df['type'] == 'CASH_OUT'].copy()\n",
    "        column1 = temp_df['oldbalanceOrg'] - temp_df['newbalanceOrig']\n",
    "        column2 = temp_df['oldbalanceDest'] - temp_df['newbalanceDest']\n",
    "        new_df = pd.DataFrame({'OriginAccount Balance Delta': column1, 'DestinationAccount Balance Delta': column2})\n",
    "        print(new_df)\n",
    "        return new_df\n",
    "\n",
    "    new_df = query(df)\n",
    "    plot = new_df.plot.scatter(x='OriginAccount Balance Delta', y='DestinationAccount Balance Delta')\n",
    "    plot.set_title('Balance Delta Scatter Plot')\n",
    "    plot.set_xlim(left=-1e3, right=1e3)\n",
    "    plot.set_ylim(bottom=-1e3, top=1e3)\n",
    "    plt.show()\n",
    "    return 'Understanding the scatter plot depicting the relationship between the delta of origin account balance and destination account balance for Cash Out transactions is critical because it enables the detection of potential irregularities or instances of fraudulent behaviour within the financial ecosystem.'\n",
    "\n",
    "visual_2(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572d06d",
   "metadata": {
    "id": "f572d06d"
   },
   "source": [
    "Use your newly-gained Pandas skills to find an insight from the dataset. You have full flexibility to go in whichever direction interests you. Please create a visual as above for this query. `visual_custom` should call `exercise_custom`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5393e5c5",
   "metadata": {
    "id": "5393e5c5"
   },
   "outputs": [],
   "source": [
    "def exercise_custom(df, step):\n",
    "    step_data = df[df['step'] == step]\n",
    "    type_counts = step_data['type'].value_counts().reset_index()\n",
    "    type_counts.columns = ['type', 'frequency']\n",
    "    \n",
    "    all_types = df['type'].unique()\n",
    "    missing_types = list(set(all_types) - set(type_counts['type']))\n",
    "    missing_counts = pd.DataFrame({'type': missing_types, 'frequency': 0})\n",
    "    \n",
    "    step_df = pd.concat([type_counts, missing_counts], ignore_index=True)\n",
    "    return step_df\n",
    "    \n",
    "def visual_custom(df, step):\n",
    "    step_df = exercise_custom(df, step)\n",
    "    \n",
    "    labels = step_df['type']\n",
    "    frequencies = step_df['frequency']\n",
    "    \n",
    "    plt.pie(frequencies, labels=labels, autopct='%1.1f%%')\n",
    "    plt.axis('equal')\n",
    "    plt.title(f'Pie Chart for Step {step}')\n",
    "    plt.show()\n",
    "    return 'The pie charts purpose in this context is to provide a visual representation of the proportional distribution of different types within a specific step.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddecc786",
   "metadata": {
    "id": "ddecc786"
   },
   "source": [
    "Submission\n",
    "\n",
    "1. Copy the exercises into `task1.py`.\n",
    "2. Upload `task1.py` to Forage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qpIxC3xgQpOo",
   "metadata": {
    "id": "qpIxC3xgQpOo"
   },
   "source": [
    "All done!\n",
    "\n",
    "Your work will be instrumental for our team's continued success."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
